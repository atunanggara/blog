{
  
    
        "post0": {
            "title": "Exploring Covid-19 Dataset",
            "content": "Summary . Visualizing Covid-19 patients number in the State of Minnesota using altair. The county data is taken from New York Times repository . . Introductions . I enjoy browsing through the data provided by the Minnesota Department of Health on Covid-19 cases daily. It provides the most up-to-date number of confirmed positive cases in the state. However, to get the historical data is a little circuitous. . So, I was thrilled to learn that the New York Times published their county-by-county Covid-19 data historically. It motivated me to create an interactive map of Minnesota and their historical data on a similar fashion as shown on the covid-19 dashboards. . In summary, using a Jupyter notebook, I want to showcase fastpages&#39; capacity to visualize interactive map and bar graph in Altair using Covid-19 data. . Results . Click on County to Filter Chart Below . Code Explanations . Here are the process to create the visuals shown above. Feel free to hit the badges above in order to see the code, or directly here. . Importing modules . I start by importing all the necessary components: . %reload_ext autoreload %autoreload 2 import pandas as pd import altair as alt import requests . I used %reload_ext autoreload Python magic in order to reload all changed modules before executing a new line. Pandas and Altair are used for the data formatting and data visualizations along with requests to obtain the json formatted data. . Data Extraction and Cleaning . New York Times County-by-county Data . I am getting the data from the New York Times repository and converting it into a pandas DataFrame: . # data from NY-Times: url=&quot;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&quot; df = pd.read_csv(url) dfmn = df[df.state==&quot;Minnesota&quot;] dfmn[&#39;date&#39;] = pd.to_datetime(dfmn[&#39;date&#39;]) . As mentioned on the their github repository: . Many state health departments choose to report cases separately when the patient’s county of residence is unknown or pending determination. In these instances, we record the county name as “Unknown.” As more information about these cases becomes available, the cumulative number of cases in “Unknown” counties may fluctuate. . I dropped the unknown number of confirmed cases because the number of confirmed cases is higher than reported on the Minnesota Department of Health web site if I include them. . # drop the null values by first finding the index of the unknown, then use list # comprehension to drop the values unknown = dfmn[dfmn.isnull().any(axis=&quot;columns&quot;)].index dfmn = dfmn.drop([i for i in unknown], axis=0) del unknown # now that there is no null value: # convert the FIPS as string in integer format to match with the json county data for Minnesota dfmn.fips = dfmn.fips.astype(int).astype(str) . However, that is not the case for death counts. The death count discrepancies are on the 27th and the 26th of March. By checking between the Minnesota Department of Health web archive and our New York Times dataset, I decided to add the unknown death count data to Hennepin county. This might not reflect the reality, but adding the data to Hennepin county makes the most sense in order to maintain anonimity and accuracy of the data due to the county having the highest number of cases in the State of Minnesota. . # dealing with discrepancy with the death count: # use: https://web.archive.org/web/*/https://www.health.state.mn.us/diseases/coronavirus/situation.html # and see the difference between the two dates of 03/28 and 03/27 # 03-28 # dfmn[(dfmn.date==&quot;2020-03-28&quot;)&amp;(dfmn.deaths != 0)] # 03-27 # dfmn[(dfmn.date==&quot;2020-03-27&quot;)&amp;(dfmn.deaths != 0)] #hide # let&#39;s add the death data into Hennepin county for 03-27: dfmn.loc[dfmn[(dfmn.county==&quot;Hennepin&quot;)&amp;(dfmn.date==&quot;2020-03-27&quot;)].index[0],&#39;deaths&#39;] = 2 # new 2020-03-27: # dfmn[(dfmn.date==&quot;2020-03-27&quot;)&amp;(dfmn.deaths != 0)] # 2020-03-26 # dfmn[(dfmn.date==&quot;2020-03-26&quot;)&amp;(dfmn.deaths != 0)] # I added 1 death data into Hennepin county for 2020-03-26 dfmn.loc[dfmn[(dfmn.county==&quot;Hennepin&quot;)&amp;(dfmn.date==&quot;2020-03-26&quot;)].index[0],&#39;deaths&#39;] = 1 . County data . The topographic and FIPS data is taken from David Eldersved&#39;s github repository. . # getting minnesota county data url_counties = &quot;https://raw.githubusercontent.com/deldersveld/topojson/master/countries/us-states/MN-27-minnesota-counties.json&quot; resp = requests.get(url_counties) data= resp.json() del resp df_county = pd.json_normalize(data[&#39;objects&#39;][&#39;cb_2015_minnesota_county_20m&#39;][&#39;geometries&#39;]) df_county = df_county[[&quot;properties.GEOID&quot;,&quot;properties.NAME&quot;]] df_county.columns = [&#39;fips&#39;,&#39;county&#39;] del data . Combining Case count and County Data . We combine the two data sources using for loop: . # Remove state column since it is all in Minnesota: df3mneasy = dfmn.drop(&#39;state&#39;,1) # grabbing all the dates in the data for the for loop uniquedate = df3mneasy.date.unique() # an empty DataFrame for the new data countycase_df = pd.DataFrame() # add 0 cases and 0 deaths for counties that do not have cases values = {&#39;cases&#39;: 0, &#39;deaths&#39;: 0} for i in uniquedate: df = df3mneasy[df3mneasy.date == i] #filter for each date df = df_county.merge(df,&#39;left&#39;) # we want to keep all the counties df[&#39;date&#39;] = df[&#39;date&#39;].fillna(i) # fill the appropriate date df = df.fillna(value=values) # fill the zero counts countycase_df = countycase_df.append(df, ignore_index=True) # new DataFrame # remove df3mneasy and uniquedate del df3mneasy, uniquedate # getting the data for the latest date dfmnlatest = countycase_df[countycase_df.date==max(countycase_df.date)] . Counting New Cases . In order to get the number of new cases, I used pandas dataframe diff to calculate the difference of consecutive rows. . # getting data to see the increment of new cases per day newcases = countycase_df.sort_values([&quot;county&quot;,&quot;date&quot;],ascending=(True,True)) # grabbing all the county in minnesota uniquecounty = newcases.county.unique() # empty_df for newcases_df = pd.DataFrame() for i in uniquecounty: df = newcases[newcases.county == i] df[&#39;newcases&#39;] = df.cases.diff() df[&#39;newdeaths&#39;] = df.deaths.diff() newcases_df = newcases_df.append(df, ignore_index=True) del newcases, uniquecounty # I drop all the NAs because that means that on the first day, there were no differences to count newcases_df = newcases_df.dropna() . Visualization Code . First off, I created a few variables needed in order to render the visuals correctly: . # inspired by # https://github.com/github/covid19-dashboard/blob/master/_notebooks/2020-03-15-us-growth-by-state-map.ipynb # to fix the altair transformation alt.data_transformers.disable_max_rows() #https://github.com/altair-viz/altair/issues/1005#issuecomment-403237407 def to_altair_datetime(dt): return alt.DateTime(year=dt.year, month=dt.month, date=dt.day, hours=dt.hour, minutes=dt.minute, seconds=dt.second, milliseconds=0.001 * dt.microsecond) # getting the maximum and minimum date dmax = (countycase_df.date.max() + pd.DateOffset(days=3)) dmin = countycase_df.date.min() # getting the current_date curr_date = countycase_df.date.max().date().strftime(&#39;%Y-%m-%d&#39;) # getting the topographic data url_counties = &quot;https://raw.githubusercontent.com/deldersveld/topojson/master/countries/us-states/MN-27-minnesota-counties.json&quot; counties = alt.topo_feature(url=url_counties, feature=&#39;cb_2015_minnesota_county_20m&#39;) . In order to connect the three graphs, I created a variable selector: . # use selector selector = alt.selection_single(empty=&#39;none&#39;, fields=[&#39;county&#39;], init={&#39;county&#39;:&#39;Hennepin&#39;}) . I chose the empty field to be equal to &#39;none&#39;, in order to clear up the binding when I do not select any county. I also picked Hennepin county as the initial choice due to it being the highest number of cases. Altair&#39;s documentation provides a good read on all the different arguments. . Here I created a variable background for the topographic map of Minnesota: . background = alt.Chart(counties).mark_geoshape( stroke=&#39;black&#39; ).transform_lookup( lookup=&#39;properties.GEOID&#39;, from_=alt.LookupData(data=dfmnlatest,key=&#39;fips&#39;, fields=[&#39;county&#39;,&#39;cases&#39;,&#39;deaths&#39;,&#39;date&#39;]) ).encode( color=alt.Color(&#39;cases:Q&#39;,scale=alt.Scale(scheme=&#39;greenblue&#39;)), tooltip=[&#39;county:N&#39;,&#39;cases:Q&#39;,&#39;deaths:Q&#39;], ).properties( width=500, height=350, title=f&#39;Total Confirmed Cases by County as of {curr_date}&#39; ).add_selection( selector ).project(&#39;albersUsa&#39;) . I combined the topojson data with the dfmnlatest DataFrame using transform_lookup. I added the selector in the add_selection statement to connect it with the other graph. Vega provided a nice selection of color schemes that can be used in the graph. . Here I created a variable newcases to graph the new cases throughout the duration of the Covid-19 data: . newcases = alt.Chart(newcases_df).mark_bar().properties( width=500, height=350, title=&quot;New Confirmed Cases by County&quot;, ).transform_filter( selector ).add_selection( selector ).encode( x=alt.X(&#39;date:T&#39;, title=&#39;Date&#39;, timeUnit=&#39;yearmonthdate&#39;, axis=alt.Axis(format=&#39;%y/%m/%d&#39;, labelAngle=-30,titleColor=&#39;black&#39;), scale=alt.Scale(domain=[to_altair_datetime(dmin), to_altair_datetime(dmax)])), y=alt.Y(&#39;newcases&#39;, axis=alt.Axis(title=&#39;# of New Confirmed Cases&#39;,titleColor=&#39;black&#39;), ), color=alt.Color(&#39;county&#39;,scale=alt.Scale(scheme=&#39;viridis&#39;)), tooltip=[&#39;county:N&#39;,&#39;date:T&#39;, alt.Tooltip(&#39;newcases:Q&#39;,title=&#39;# of new cases&#39;), alt.Tooltip(&#39;newdeaths:Q&#39;, title=&#39;# of new deaths&#39;)] ) . The transform_filter tranform the filter based on the selection of our click. I used Tooltip wrapper for renaming the title of the column being grabbed from the newcases_df DataFrame. . Here I created a chart variable to show the breakdown of total confirmed cases in Minnesota: . chart = alt.Chart(dfmn).mark_bar().properties( width=500, height=350, title=&quot;Total Confirmed Cases by County&quot;, ).add_selection( selector ).encode( x=alt.X(&#39;date:T&#39;, title=&#39;Date&#39;, timeUnit=&#39;yearmonthdate&#39;, axis=alt.Axis(format=&#39;%y/%m/%d&#39;, labelAngle=-30,titleColor=&#39;black&#39;), scale=alt.Scale(domain=[to_altair_datetime(dmin), to_altair_datetime(dmax)])), y=alt.Y(&#39;sum(cases)&#39;, axis=alt.Axis(title=&#39;# of Total Cases&#39;,titleColor=&#39;black&#39;), ), color=alt.Color(&#39;county&#39;,scale=alt.Scale(scheme=&#39;viridis&#39;)), order=alt.Order( &#39;cases&#39; ), opacity=alt.condition(selector, alt.value(1), alt.value(0.5)), tooltip=[&#39;county:N&#39;,&#39;date:T&#39;,&#39;cases:Q&#39;, &#39;deaths:Q&#39;] ) . Finally, I created final_chart to combine all the three graphs together: . final_chart = alt.vconcat( background, newcases, chart, ).resolve_scale( shape=&#39;independent&#39;, ).configure( padding={&#39;left&#39;:10, &#39;bottom&#39;:0} ).configure_axis( labelFontSize=10, labelPadding=10, titleFontSize=12, ).configure_view( stroke=None ) final_chart . Concluding thoughts . I hope you enjoy the visualization and the breakdown summary on the process that I take to create this Altair visualization. The module is full of wonderful ways to create visualization that can enhance your analysis. Feel free to explore their gallery for more awesome graphs. . If you have any comments or would like to connect, add me on my LinkedIn profile! .",
            "url": "https://atunanggara.github.io/blog/jupyter/covid-19/altair/2020/04/02/covid-19-dataset.html",
            "relUrl": "/jupyter/covid-19/altair/2020/04/02/covid-19-dataset.html",
            "date": " • Apr 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "First Post - Setting up Index Page and About Me on fastpages",
            "content": "This first post will be about how I set up my Index Page and About Me for this fastpages site along with an introduction on how I stumble upon the platform. . Introduction . In the past couple of weeks, the Introduction to Machine Learning for Coders by Jeremy Howard has helped me better understand Random Forest technique and provided me with a nice introduction to deep learning. . . Then, Covid-19 happened. . Since I am a fan of fast.ai, I listened to Jeremy’s YouTube summary on the situation. At the end of his video, he pointed his audience to the fast.ai forum. . When I searched through it, I stumbled upon the beautiful Covid-19 Dashboards website. The beauty and simplicity of the format is what really sold me into creating my site using this fastpages. . Setting up . In terms of setting up fastpages, it is pretty self-explanatory. I am thankful to Abdul Majed for his nice walk-through video that helped reassure me that I am on the right track. . Yet, I find myself stumbling through what would be the next step for me once I have the blog template up and running. So, here is my attempt to share with you what I have done to customize the Index Page and About Me page. . Index Page . The Index Page can be accessed under index.html on the main repository: . Once I hit the Edit this file button, I used my markdown skill to edit the pages: . . A few things to note: . The Index Page is created using markdown, even though it is an html file. If you are not familiar with markdown, here are some guides from fastpages or from github | Line 6 uses &lt;!-- in the beginning and --&gt; at the end to comment the index.html file. Since markdown do not have the capacity to comment, I used html comment tag instead. | The welcome image is taken from flickr. I embedded the image by uploading it into github repository images folder and coding it into the page (![edit pages](/blog/images/Index-playaround.png)). | . About Me . The About Me page can be accessed under _pages/about.md on the main repository: . Same process as the Index Page setup above. . Summary . I hope that this post will help others who are trying to set up their Index Page and About Me fastpages site. Feel free to reach out to me on LinkedIn or Twitter if you have any questions! .",
            "url": "https://atunanggara.github.io/blog/fastpages/2020/03/25/First-Post.html",
            "relUrl": "/fastpages/2020/03/25/First-Post.html",
            "date": " • Mar 25, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://atunanggara.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Microsoft Word Example Post",
            "content": "When writing a blog post with Microsoft Word – the filename becomes the title. In this case the file name is “2020-01-01-Microsoft-Word-Example-Post.docx”. . There is minimal support for Word documents in fastpages compared to Jupyter notebooks. Some known limitations: . alt text in Word documents are not yet supported by fastpages, and will break links to images. . | You can only specify front matter for Word documents globally. See the README for more details. . | . For greater control over the content produced from Word documents, you will need to convert Word to markdown files manually. You can follow the steps in this blog post, which walk you through how to use pandoc to do the conversion. Note: If you wish to customize your Word generated blog post in markdown, make sure you delete your Word document from the _word directory so your markdown file doesn’t get overwritten! . If your primary method of writing blog posts is Word documents, and you plan on always manually editing Word generated markdown files, you are probably better off using fast_template instead of fastpages. . The material below is a reproduction of this blog post, and serves as an illustrative example. . Maintaining a healthy open source project can entail a huge amount of toil. Popular projects often have orders of magnitude more users and episodic contributors opening issues and PRs than core maintainers capable of handling these issues. . Consider this graphic prepared by the NumFOCUS foundation showing the number of maintainers for three widely used scientific computing projects: . . We can see that across these three projects, there is a very low ratio maintainers to users. Fixing this problem is not an easy task and likely requires innovative solutions to address the economics as well as tools. . Due to its recent momentum and popularity, Kubeflow suffers from a similar fate as illustrated by the growth of new issues opened: . . Source: “TensorFlow World 2019, Automating Your Developer Workflow With ML” . Coincidentally, while building out end to end machine learning examples for Kubeflow, we built two examples using publicly available GitHub data: GitHub Issue Summarization and Code Search. While these tutorials were useful for demonstrating components of Kubeflow, we realized that we could take this a step further and build concrete data products that reduce toil for maintainers. . This is why we started the project kubeflow/code-intelligence, with the goals of increasing project velocity and health using data driven tools. Below are two projects we are currently experimenting with : . Issue Label Bot: This is a bot that automatically labels GitHub issues using Machine Learning. This bot is a GitHub App that was originally built for Kubeflow but is now also used by several large open source projects. The current version of this bot only applies a very limited set of labels, however we are currently A/B testing new models that allow personalized labels. Here is a blog post discussing this project in more detail. . | Issue Triage GitHub Action: to compliment the Issue Label Bot, we created a GitHub Action that automatically adds / removes Issues to the Kubeflow project board tracking issues needing triage. . | Together these projects allow us to reduce the toil of triaging issues. The GitHub Action makes it much easier for the Kubeflow maintainers to track issues needing triage. With the label bot we have taken the first steps in using ML to replace human intervention. We plan on using features extracted by ML to automate more steps in the triage process to further reduce toil. . Building Solutions with GitHub Actions . One of the premises of Kubeflow is that a barrier to building data driven, ML powered solutions is getting models into production and integrated into a solution. In the case of building models to improve OSS project health, that often means integrating with GitHub where the project is hosted. . We are really excited by GitHub’s newly released feature GitHub Actions because we think it will make integrating ML with GitHub much easier. . For simple scripts, like the issue triage script, GitHub actions make it easy to automate executing the script in response to GitHub events without having to build and host a GitHub app. . To automate adding/removing issues needing triage to a Kanban board we wrote a simple python script that interfaces with GitHub’s GraphQL API to modify issues. . As we continue to iterate on ML Models to further reduce toil, GitHub Actions will make it easy to leverage Kubeflow to put our models into production faster. A number of prebuilt GitHub Actions make it easy to create Kubernetes resources in response to GitHub events. For example, we have created GitHub Actions to launch Argo Workflows. This means once we have a Kubernetes job or workflow to perform inference we can easily integrate the model with GitHub and have the full power of Kubeflow and Kubernetes (eg. GPUs). We expect this will allow us to iterate much faster compared to building and maintaining GitHub Apps. . Call To Action . We have a lot more work to do in order to achieve our goal of reducing the amount of toil involved in maintaining OSS projects. If your interested in helping out here’s a couple of issues to get started: . Help us create reports that pull and visualize key performance indicators (KPI). https://github.com/kubeflow/code-intelligence/issues/71 . We have defined our KPI here: issue #19 | . | Combine repo specific and non-repo specific label predictions: https://github.com/kubeflow/code-intelligence/issues/70 . | . In addition to the aforementioned issues we welcome contributions for these other issues in our repo. .",
            "url": "https://atunanggara.github.io/blog/2020/01/01/Microsoft-Word-Example-Post.html",
            "relUrl": "/2020/01/01/Microsoft-Word-Example-Post.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I got interested in data science after receiving my Ph.D. in the computational chemical engineering catalysis area and did my post-doc in the First Year of Studies program at the University of Notre Dame. . My post-doc experience provided me the opportunity to work with various data science techniques. Sentiment analysis, n-gram analysis, and topic modeling were some of the techniques that I have performed on various textual data, including students’ reflection and survey results. Creating statistical summary and Tableau dashboard for various stakeholders in the university have also been a part of my experience. . Currently, I am continuing to level up my data science skills. That includes being a part of the deep learning study group in the community. .",
          "url": "https://atunanggara.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://atunanggara.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}